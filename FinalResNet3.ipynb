{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayra-13/LeafCure/blob/main/FinalResNet3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "OMLoxwDIJ6Ud"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn as nn\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from PIL import Image, ImageFile\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure PIL doesn't crash on truncated files\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# Custom loader to handle corrupted images\n",
        "def safe_pil_loader(path):\n",
        "    try:\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "    except OSError as e:\n",
        "        warnings.warn(f\"Skipping corrupted image: {path} ({e})\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "IxMxLuSRMoAx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PCaQ8Ik4fdY",
        "outputId": "da038eb6-2556-46ed-8339-3a5cf9339865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZPcEW1q6yrDK"
      },
      "outputs": [],
      "source": [
        "# Paths\n",
        "# Replace with your main folder path\n",
        "source_dir = \"drive/MyDrive/Model/Rice_Leaf_AUG1\"\n",
        "destination_dir = \"drive/MyDrive/Model/Dest_Rice_Leaf_AUG1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CQbyBm97pqL",
        "outputId": "1a2a4ef1-bc5b-4327-a7d2-649bb2f93615"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bacterial Leaf Blight',\n",
              " 'Healthy Rice Leaf',\n",
              " 'Neck_Blast',\n",
              " 'Narrow Brown Leaf Spot',\n",
              " 'Leaf Blast',\n",
              " 'Sheath Blight',\n",
              " 'Brown Spot',\n",
              " 'Leaf scald',\n",
              " 'Rice Hispa']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "os.listdir(source_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQl8JPOx7tBx",
        "outputId": "bab0f5f6-5e0f-4514-83ab-c8d608ce3708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images have been copied successfully.\n"
          ]
        }
      ],
      "source": [
        "# Ensure the destination directory exists\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "# Walk through the source directory\n",
        "for root, dirs, files in os.walk(source_dir):\n",
        "    # Get only the image files (modify extensions if needed)\n",
        "    image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "\n",
        "    if image_files:  # If there are images in the folder\n",
        "        # Randomly select half of the images\n",
        "        num_to_copy = len(image_files) // 2\n",
        "        images_to_copy = random.sample(image_files, num_to_copy)\n",
        "\n",
        "        # Create the corresponding subdirectory in the destination folder\n",
        "        relative_path = os.path.relpath(root, source_dir)\n",
        "        dest_subdir = os.path.join(destination_dir, relative_path)\n",
        "        os.makedirs(dest_subdir, exist_ok=True)\n",
        "\n",
        "        # Copy the selected images\n",
        "        for image in images_to_copy:\n",
        "            src_path = os.path.join(root, image)\n",
        "            dest_path = os.path.join(dest_subdir, image)\n",
        "            shutil.copy2(src_path, dest_path)  # Use copy2 to preserve metadata\n",
        "\n",
        "print(\"Images have been copied successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAyzFOfI7-sE",
        "outputId": "89252355-ebe9-40b5-ecfb-11629bfb48fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bacterial Leaf Blight',\n",
              " 'Healthy Rice Leaf',\n",
              " 'Neck_Blast',\n",
              " 'Narrow Brown Leaf Spot',\n",
              " 'Leaf Blast',\n",
              " 'Sheath Blight',\n",
              " 'Brown Spot',\n",
              " 'Leaf scald',\n",
              " 'Rice Hispa']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "os.listdir(destination_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbN3rXUe8i6e",
        "outputId": "4c73f1ac-40a6-40a3-98cc-52b4a0420bbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset split into train, val, and test sets.\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "output_dir = \"drive/MyDrive/Model/RiceDatatest\"  # Replace with your output path\n",
        "\n",
        "# Ratios for splitting\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.2\n",
        "test_ratio = 0.1\n",
        "\n",
        "# Ensure output directories exist\n",
        "for split in ['train', 'val', 'test']:\n",
        "    os.makedirs(os.path.join(output_dir, split), exist_ok=True)\n",
        "\n",
        "# Split the dataset\n",
        "for root, dirs, files in os.walk(source_dir):\n",
        "    # Assuming your source directory has subfolders representing classes\n",
        "    for class_name in dirs: # Iterate through each class subfolder\n",
        "        class_dir = os.path.join(root, class_name) # Get path to class subfolder\n",
        "        image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "\n",
        "        if image_files:  # If there are images in the class folder\n",
        "            random.shuffle(image_files)\n",
        "            num_images = len(image_files)\n",
        "            train_end = int(train_ratio * num_images)\n",
        "            val_end = train_end + int(val_ratio * num_images)\n",
        "\n",
        "            splits = {\n",
        "                'train': image_files[:train_end],\n",
        "                'val': image_files[train_end:val_end],\n",
        "                'test': image_files[val_end:]\n",
        "            }\n",
        "\n",
        "            for split, split_files in splits.items():\n",
        "                split_dir = os.path.join(output_dir, split, class_name) # Create class subfolder in split directory\n",
        "                os.makedirs(split_dir, exist_ok=True)\n",
        "                for image in split_files:\n",
        "                    shutil.copy2(os.path.join(class_dir, image), os.path.join(split_dir, image))\n",
        "\n",
        "print(\"Dataset split into train, val, and test sets.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rb9tWdghCEi6"
      },
      "outputs": [],
      "source": [
        "data_dir = \"drive/MyDrive/Model/RiceDatatest\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qed1S0P3-ECP",
        "outputId": "3419d41a-61c9-4dce-a36f-7f3a1a4ed566"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'val', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "os.listdir(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFDZ9nG79Ui9",
        "outputId": "4672b86a-ea0d-40d4-ad95-c4729b679030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-d1e8bffda8af>:31: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # For mixed precision training\n"
          ]
        }
      ],
      "source": [
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform,loader=safe_pil_loader)\n",
        "val_data = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform,loader=safe_pil_loader)\n",
        "test_data = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=transform,loader=safe_pil_loader)\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Load ResNet50\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, len(train_data.classes))  # Adjust output for the number of classes\n",
        "model = model.to(device)  # Move the model to the correct device\n",
        "\n",
        "# Define optimizer, loss, and scheduler\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "scaler = GradScaler()  # For mixed precision training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} - Training\")\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        # Move inputs and labels to the device\n",
        "        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass with mixed precision\n",
        "        with autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimizer step\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # Accumulate training loss\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Log progress every 50 batches or at the end\n",
        "        if (batch_idx + 1) % 50 == 0 or (batch_idx + 1) == len(train_loader):\n",
        "            print(f\"  Batch {batch_idx+1}/{len(train_loader)}: Loss {loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    print(f\"Training Complete: Average Loss: {avg_train_loss:.4f}\")\n",
        "    return avg_train_loss\n",
        "\n",
        "\n",
        "# Validation function\n",
        "def validate_one_epoch(model, val_loader, criterion, device, epoch):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} - Validation\")\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            # Move inputs and labels to the device\n",
        "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "            # Forward pass with mixed precision\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # Accumulate validation loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = correct / total\n",
        "    print(f\"Validation Complete: Average Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
        "    return avg_val_loss, val_accuracy\n"
      ],
      "metadata": {
        "id": "cOw9PE53KJ9_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training loop\n",
        "epochs = 20\n",
        "best_val_accuracy = 0\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, epoch)\n",
        "    val_loss, val_accuracy = validate_one_epoch(model, val_loader, criterion, device, epoch)\n",
        "\n",
        "    # Save the best model\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        torch.save(model.state_dict(), \"best_model_resnet50.pth\")\n",
        "        print(f\"  New best model saved with Accuracy: {best_val_accuracy:.4f}\")\n",
        "\n",
        "    # Adjust learning rate\n",
        "    scheduler.step()\n",
        "    print(f\"Learning rate adjusted to: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o86V0tZgKM5n",
        "outputId": "327c4640-f086-4708-e54f-132ec419ae82"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "\n",
            "Epoch 1 - Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-39afbed73011>:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 50/92: Loss 1.1654\n",
            "  Batch 92/92: Loss 0.8409\n",
            "Training Complete: Average Loss: 1.3229\n",
            "\n",
            "Epoch 1 - Validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-39afbed73011>:50: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Complete: Average Loss: 1.0422, Accuracy: 0.6151\n",
            "  New best model saved with Accuracy: 0.6151\n",
            "Learning rate adjusted to: 0.001000\n",
            "\n",
            "Epoch 2 - Training\n",
            "  Batch 50/92: Loss 0.8434\n",
            "  Batch 92/92: Loss 1.0691\n",
            "Training Complete: Average Loss: 0.9227\n",
            "\n",
            "Epoch 2 - Validation\n",
            "Validation Complete: Average Loss: 1.0244, Accuracy: 0.6295\n",
            "  New best model saved with Accuracy: 0.6295\n",
            "Learning rate adjusted to: 0.001000\n",
            "\n",
            "Epoch 3 - Training\n",
            "  Batch 50/92: Loss 0.6632\n",
            "  Batch 92/92: Loss 1.0860\n",
            "Training Complete: Average Loss: 0.7419\n",
            "\n",
            "Epoch 3 - Validation\n",
            "Validation Complete: Average Loss: 0.6992, Accuracy: 0.7518\n",
            "  New best model saved with Accuracy: 0.7518\n",
            "Learning rate adjusted to: 0.001000\n",
            "\n",
            "Epoch 4 - Training\n",
            "  Batch 50/92: Loss 0.4934\n",
            "  Batch 92/92: Loss 0.4275\n",
            "Training Complete: Average Loss: 0.5993\n",
            "\n",
            "Epoch 4 - Validation\n",
            "Validation Complete: Average Loss: 0.8259, Accuracy: 0.7110\n",
            "Learning rate adjusted to: 0.001000\n",
            "\n",
            "Epoch 5 - Training\n",
            "  Batch 50/92: Loss 0.4721\n",
            "  Batch 92/92: Loss 0.1908\n",
            "Training Complete: Average Loss: 0.4961\n",
            "\n",
            "Epoch 5 - Validation\n",
            "Validation Complete: Average Loss: 0.6402, Accuracy: 0.7686\n",
            "  New best model saved with Accuracy: 0.7686\n",
            "Learning rate adjusted to: 0.001000\n",
            "\n",
            "Epoch 6 - Training\n",
            "  Batch 50/92: Loss 0.1728\n",
            "  Batch 92/92: Loss 0.6519\n",
            "Training Complete: Average Loss: 0.4485\n",
            "\n",
            "Epoch 6 - Validation\n",
            "Validation Complete: Average Loss: 2.1020, Accuracy: 0.5719\n",
            "Learning rate adjusted to: 0.001000\n",
            "\n",
            "Epoch 7 - Training\n",
            "  Batch 50/92: Loss 0.3132\n",
            "  Batch 92/92: Loss 1.1639\n",
            "Training Complete: Average Loss: 0.3890\n",
            "\n",
            "Epoch 7 - Validation\n",
            "Validation Complete: Average Loss: 0.9218, Accuracy: 0.7194\n",
            "Learning rate adjusted to: 0.000100\n",
            "\n",
            "Epoch 8 - Training\n",
            "  Batch 50/92: Loss 0.2062\n",
            "  Batch 92/92: Loss 0.1149\n",
            "Training Complete: Average Loss: 0.2324\n",
            "\n",
            "Epoch 8 - Validation\n",
            "Validation Complete: Average Loss: 0.3268, Accuracy: 0.8837\n",
            "  New best model saved with Accuracy: 0.8837\n",
            "Learning rate adjusted to: 0.000100\n",
            "\n",
            "Epoch 9 - Training\n",
            "  Batch 50/92: Loss 0.0340\n",
            "  Batch 92/92: Loss 0.1770\n",
            "Training Complete: Average Loss: 0.1377\n",
            "\n",
            "Epoch 9 - Validation\n",
            "Validation Complete: Average Loss: 0.3168, Accuracy: 0.8849\n",
            "  New best model saved with Accuracy: 0.8849\n",
            "Learning rate adjusted to: 0.000100\n",
            "\n",
            "Epoch 10 - Training\n",
            "  Batch 50/92: Loss 0.0850\n",
            "  Batch 92/92: Loss 0.2476\n",
            "Training Complete: Average Loss: 0.1054\n",
            "\n",
            "Epoch 10 - Validation\n",
            "Validation Complete: Average Loss: 0.2944, Accuracy: 0.8921\n",
            "  New best model saved with Accuracy: 0.8921\n",
            "Learning rate adjusted to: 0.000100\n",
            "\n",
            "Epoch 11 - Training\n",
            "  Batch 50/92: Loss 0.0631\n",
            "  Batch 92/92: Loss 0.0389\n",
            "Training Complete: Average Loss: 0.0785\n",
            "\n",
            "Epoch 11 - Validation\n",
            "Validation Complete: Average Loss: 0.2855, Accuracy: 0.9053\n",
            "  New best model saved with Accuracy: 0.9053\n",
            "Learning rate adjusted to: 0.000100\n",
            "\n",
            "Epoch 12 - Training\n",
            "  Batch 50/92: Loss 0.1719\n",
            "  Batch 92/92: Loss 0.0801\n",
            "Training Complete: Average Loss: 0.0595\n",
            "\n",
            "Epoch 12 - Validation\n",
            "Validation Complete: Average Loss: 0.3059, Accuracy: 0.9041\n",
            "Learning rate adjusted to: 0.000100\n",
            "\n",
            "Epoch 13 - Training\n",
            "  Batch 50/92: Loss 0.0199\n",
            "  Batch 92/92: Loss 0.0973\n",
            "Training Complete: Average Loss: 0.0450\n",
            "\n",
            "Epoch 13 - Validation\n",
            "Validation Complete: Average Loss: 0.3095, Accuracy: 0.9137\n",
            "  New best model saved with Accuracy: 0.9137\n",
            "Learning rate adjusted to: 0.000100\n",
            "\n",
            "Epoch 14 - Training\n",
            "  Batch 50/92: Loss 0.0909\n",
            "  Batch 92/92: Loss 0.1383\n",
            "Training Complete: Average Loss: 0.0388\n",
            "\n",
            "Epoch 14 - Validation\n",
            "Validation Complete: Average Loss: 0.3235, Accuracy: 0.9089\n",
            "Learning rate adjusted to: 0.000010\n",
            "\n",
            "Epoch 15 - Training\n",
            "  Batch 50/92: Loss 0.1230\n",
            "  Batch 92/92: Loss 0.0136\n",
            "Training Complete: Average Loss: 0.0296\n",
            "\n",
            "Epoch 15 - Validation\n",
            "Validation Complete: Average Loss: 0.3199, Accuracy: 0.9197\n",
            "  New best model saved with Accuracy: 0.9197\n",
            "Learning rate adjusted to: 0.000010\n",
            "\n",
            "Epoch 16 - Training\n",
            "  Batch 50/92: Loss 0.0221\n",
            "  Batch 92/92: Loss 0.1991\n",
            "Training Complete: Average Loss: 0.0266\n",
            "\n",
            "Epoch 16 - Validation\n",
            "Validation Complete: Average Loss: 0.3369, Accuracy: 0.9053\n",
            "Learning rate adjusted to: 0.000010\n",
            "\n",
            "Epoch 17 - Training\n",
            "  Batch 50/92: Loss 0.0069\n",
            "  Batch 92/92: Loss 0.4372\n",
            "Training Complete: Average Loss: 0.0247\n",
            "\n",
            "Epoch 17 - Validation\n",
            "Validation Complete: Average Loss: 0.3392, Accuracy: 0.9125\n",
            "Learning rate adjusted to: 0.000010\n",
            "\n",
            "Epoch 18 - Training\n",
            "  Batch 50/92: Loss 0.0052\n",
            "  Batch 92/92: Loss 0.2032\n",
            "Training Complete: Average Loss: 0.0248\n",
            "\n",
            "Epoch 18 - Validation\n",
            "Validation Complete: Average Loss: 0.3366, Accuracy: 0.9101\n",
            "Learning rate adjusted to: 0.000010\n",
            "\n",
            "Epoch 19 - Training\n",
            "  Batch 50/92: Loss 0.0128\n",
            "  Batch 92/92: Loss 0.0024\n",
            "Training Complete: Average Loss: 0.0158\n",
            "\n",
            "Epoch 19 - Validation\n",
            "Validation Complete: Average Loss: 0.3378, Accuracy: 0.9161\n",
            "Learning rate adjusted to: 0.000010\n",
            "\n",
            "Epoch 20 - Training\n",
            "  Batch 50/92: Loss 0.0037\n",
            "  Batch 92/92: Loss 0.0012\n",
            "Training Complete: Average Loss: 0.0189\n",
            "\n",
            "Epoch 20 - Validation\n",
            "Validation Complete: Average Loss: 0.3468, Accuracy: 0.9161\n",
            "Learning rate adjusted to: 0.000010\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VWAixJ4wAAE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af63adb6-ad67-4814-f5be-67ee5e910ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing the model on the test dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-fed287d9e1aa>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"best_model_resnet50.pth\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Complete: Average Loss: 0.4126, Accuracy: 0.8915\n"
          ]
        }
      ],
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load(\"best_model_resnet50.pth\"))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "test_loss = 0\n",
        "\n",
        "print(\"\\nTesting the model on the test dataset...\")\n",
        "with torch.no_grad():  # No gradient calculations for inference\n",
        "    for inputs, labels in test_loader:\n",
        "        # Move inputs and labels to the same device as the model\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)  # Calculate loss for testing\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Predictions\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "# Calculate final test accuracy and average loss\n",
        "test_accuracy = correct / total\n",
        "test_loss /= len(test_loader)\n",
        "\n",
        "print(f\"Test Complete: Average Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNs/jQOx1coCf5bjC8qXwDv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}